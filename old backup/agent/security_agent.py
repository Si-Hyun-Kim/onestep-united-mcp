#!/usr/bin/env python3
"""
AI ê¸°ë°˜ ë³´ì•ˆ ì—ì´ì „íŠ¸
Ollama Qwen3ë¥¼ ì‚¬ìš©í•œ ë¡œê·¸ ë¶„ì„ ë° ìžë™ ë£° ìƒì„±
"""

import asyncio
import json
import yaml
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
from ollama_analyzer import OllamaAnalyzer
from rule_generator import AIRuleGenerator
import sys
sys.path.append('../mcp_server')
from log_collectors import SuricataCollector, HexStrikeCollector, LogAnalyzer
from rule_manager import SuricataRuleManager

class SecurityAgent:
    """AI ê¸°ë°˜ ë³´ì•ˆ ìžë™í™” ì—ì´ì „íŠ¸"""
    
    def __init__(self, config_path: str = "./config.yaml"):
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config(config_path)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.suricata_collector = SuricataCollector(
            self.config['suricata']['log_path']
        )
        self.hexstrike_collector = HexStrikeCollector(
            self.config['hexstrike']['log_path']
        )
        self.rule_manager = SuricataRuleManager(
            self.config['suricata']['rules_path'],
            self.config['suricata']['custom_rules_path']
        )
        
        # AI ë¶„ì„ê¸°
        self.ollama_analyzer = OllamaAnalyzer(
            host=self.config['ollama']['host'],
            model=self.config['ollama']['model']
        )
        
        # ë£° ìƒì„±ê¸°
        self.rule_generator = AIRuleGenerator(
            self.ollama_analyzer,
            self.rule_manager
        )
        
        # ìƒíƒœ
        self.is_running = False
        self.blocked_ips = set()
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬
        self.log_dir = Path("./logs/agent")
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    def _load_config(self, config_path: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            return self._default_config()
    
    def _default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'agent': {
                'name': 'SecurityAgent',
                'check_interval': 30
            },
            'ollama': {
                'host': 'http://localhost:11434',
                'model': 'qwen2.5:7b',
                'temperature': 0.3,
                'max_tokens': 2000
            },
            'suricata': {
                'log_path': '/var/log/suricata/eve.json',
                'rules_path': '/etc/suricata/rules',
                'custom_rules_path': './rules/custom/auto_generated.rules'
            },
            'hexstrike': {
                'log_path': './logs/hexstrike'
            },
            'detection': {
                'alert_threshold': 5,
                'time_window': 300,
                'severity_weights': {
                    'critical': 10,
                    'high': 5,
                    'medium': 2,
                    'low': 1
                }
            },
            'auto_response': {
                'enabled': True,
                'block_threshold': 20,
                'whitelist': ['127.0.0.1', 'localhost']
            }
        }
    
    async def start(self):
        """ì—ì´ì „íŠ¸ ì‹œìž‘"""
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘  ðŸ¤– AI Security Agent Starting...           â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        print()
        print(f"âš™ï¸  Agent: {self.config['agent']['name']}")
        print(f"âš™ï¸  AI Model: {self.config['ollama']['model']}")
        print(f"âš™ï¸  Check Interval: {self.config['agent']['check_interval']}s")
        print(f"âš™ï¸  Auto Response: {self.config['auto_response']['enabled']}")
        print()
        
        # Ollama ì—°ê²° í™•ì¸
        if not await self.ollama_analyzer.check_connection():
            print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("   ollama serve ëª…ë ¹ìœ¼ë¡œ Ollamaë¥¼ ì‹œìž‘í•˜ì„¸ìš”.")
            return
        
        print("âœ… Ollama ì—°ê²° ì„±ê³µ")
        print()
        
        self.is_running = True
        
        try:
            while self.is_running:
                await self._analysis_cycle()
                await asyncio.sleep(self.config['agent']['check_interval'])
        
        except KeyboardInterrupt:
            print("\nðŸ›‘ Agent stopping...")
            self.is_running = False
    
    async def _analysis_cycle(self):
        """ë¶„ì„ ì‚¬ì´í´"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"\n[{timestamp}] ðŸ” Starting analysis cycle...")
        
        try:
            # 1. ë¡œê·¸ ìˆ˜ì§‘
            print("  ðŸ“Š Collecting logs...")
            suricata_logs = await self.suricata_collector.get_recent_logs(100)
            hexstrike_logs = await self.hexstrike_collector.get_recent_logs(50)
            
            print(f"     Suricata: {len(suricata_logs)} alerts")
            print(f"     HexStrike: {len(hexstrike_logs)} attacks")
            
            if not suricata_logs and not hexstrike_logs:
                print("  â„¹ï¸  No new logs to analyze")
                return
            
            # 2. AI ë¶„ì„
            print("  ðŸ§  Analyzing with AI...")
            analysis_result = await self._ai_analysis(suricata_logs, hexstrike_logs)
            
            # 3. ìœ„í˜‘ íƒì§€
            threats = self._detect_threats(suricata_logs)
            
            if threats:
                print(f"  ðŸš¨ Detected {len(threats)} threats")
                
                for threat in threats:
                    print(f"\n  âš ï¸  Threat: {threat['ip']}")
                    print(f"     Score: {threat['score']}")
                    print(f"     Reason: {threat['reason']}")
                    
                    # ìžë™ ëŒ€ì‘
                    if self.config['auto_response']['enabled']:
                        await self._auto_respond(threat)
            
            # 4. ë£° ìƒì„± (AI ì¶”ì²œ)
            if analysis_result.get('should_create_rules', False):
                print("\n  ðŸ“ AI recommends creating new rules...")
                await self._generate_rules(analysis_result)
            
            # 5. Red vs Blue ë¹„êµ
            if hexstrike_logs:
                metrics = LogAnalyzer.calculate_metrics(suricata_logs, hexstrike_logs)
                print(f"\n  ðŸ“ˆ Detection Metrics:")
                print(f"     Detection Rate: {metrics['detection_rate']}%")
                print(f"     False Positives: {metrics['false_positives']}")
                print(f"     False Negatives: {metrics['false_negatives']}")
        
        except Exception as e:
            print(f"  âŒ Error during analysis: {e}")
            self._log_error(str(e))
    
    async def _ai_analysis(self, suricata_logs: List[Dict], hexstrike_logs: List[Dict]) -> Dict:
        """AI ê¸°ë°˜ ë¡œê·¸ ë¶„ì„"""
        # ë¡œê·¸ ìš”ì•½
        log_summary = {
            "suricata": {
                "total": len(suricata_logs),
                "by_severity": self._group_by_severity(suricata_logs),
                "top_ips": self._get_top_ips(suricata_logs, 5),
                "top_signatures": self._get_top_signatures(suricata_logs, 5)
            },
            "hexstrike": {
                "total": len(hexstrike_logs),
                "by_attack_type": self._group_by_attack_type(hexstrike_logs),
                "success_rate": self._calculate_success_rate(hexstrike_logs)
            }
        }
        
        # AIì—ê²Œ ë¶„ì„ ìš”ì²­
        prompt = self._create_analysis_prompt(log_summary)
        
        try:
            ai_response = await self.ollama_analyzer.analyze(prompt)
            
            # AI ì‘ë‹µ íŒŒì‹±
            return self._parse_ai_response(ai_response)
        
        except Exception as e:
            print(f"  âš ï¸  AI analysis failed: {e}")
            return {
                "should_create_rules": False,
                "recommendations": []
            }
    
    def _create_analysis_prompt(self, log_summary: Dict) -> str:
        """AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ë‹¹ì‹ ì€ ë³´ì•ˆ ì „ë¬¸ê°€ AIìž…ë‹ˆë‹¤. ë‹¤ìŒ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ê¶Œìž¥ ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”.

# Suricata IPS ë¡œê·¸
- ì´ ì•Œë¦¼: {log_summary['suricata']['total']}
- ì‹¬ê°ë„ë³„:
  * Critical: {log_summary['suricata']['by_severity'].get('critical', 0)}
  * High: {log_summary['suricata']['by_severity'].get('high', 0)}
  * Medium: {log_summary['suricata']['by_severity'].get('medium', 0)}
  * Low: {log_summary['suricata']['by_severity'].get('low', 0)}

- ìƒìœ„ ê³µê²© IP: {', '.join(log_summary['suricata']['top_ips'])}
- ìƒìœ„ ì‹œê·¸ë‹ˆì²˜: {', '.join(log_summary['suricata']['top_signatures'])}

# HexStrike ê³µê²© ë¡œê·¸
- ì´ ê³µê²©: {log_summary['hexstrike']['total']}
- ê³µê²© ìœ í˜•ë³„: {json.dumps(log_summary['hexstrike']['by_attack_type'], ensure_ascii=False)}
- ì„±ê³µë¥ : {log_summary['hexstrike']['success_rate']}%

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”:
{{
  "threat_level": "low|medium|high|critical",
  "should_create_rules": true|false,
  "recommended_actions": ["action1", "action2", ...],
  "rule_suggestions": [
    {{
      "type": "block_ip|port_scan|brute_force|sql_injection|xss",
      "reason": "ì´ìœ  ì„¤ëª…",
      "priority": 1-3
    }}
  ],
  "analysis_summary": "ì¢…í•© ë¶„ì„ ê²°ê³¼"
}}
"""
    
    def _parse_ai_response(self, ai_response: str) -> Dict:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ
            json_start = ai_response.find('{')
            json_end = ai_response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = ai_response[json_start:json_end]
                return json.loads(json_str)
            
            return {
                "should_create_rules": False,
                "recommendations": []
            }
        
        except Exception:
            return {
                "should_create_rules": False,
                "recommendations": []
            }
    
    def _detect_threats(self, logs: List[Dict]) -> List[Dict]:
        """ê·œì¹™ ê¸°ë°˜ ìœ„í˜‘ íƒì§€"""
        from collections import defaultdict
        
        ip_stats = defaultdict(lambda: {
            'count': 0,
            'score': 0,
            'signatures': set(),
            'severities': []
        })
        
        # ë¡œê·¸ ì§‘ê³„
        for log in logs:
            ip = log['src_ip']
            
            if ip in self.config['auto_response']['whitelist']:
                continue
            
            ip_stats[ip]['count'] += 1
            ip_stats[ip]['signatures'].add(log['signature'])
            ip_stats[ip]['severities'].append(log['severity'])
            
            # ì‹¬ê°ë„ ê°€ì¤‘ì¹˜
            weight = self.config['detection']['severity_weights'].get(
                log['severity'], 1
            )
            ip_stats[ip]['score'] += weight
        
        # ìœ„í˜‘ íŒë‹¨
        threats = []
        threshold = self.config['detection']['alert_threshold']
        block_threshold = self.config['auto_response']['block_threshold']
        
        for ip, stats in ip_stats.items():
            if stats['count'] >= threshold or stats['score'] >= block_threshold:
                threats.append({
                    'ip': ip,
                    'count': stats['count'],
                    'score': stats['score'],
                    'signatures': list(stats['signatures']),
                    'reason': self._determine_threat_reason(stats)
                })
        
        return threats
    
    def _determine_threat_reason(self, stats: Dict) -> str:
        """ìœ„í˜‘ ì‚¬ìœ  ê²°ì •"""
        if stats['count'] >= 10:
            return f"High alert count ({stats['count']})"
        elif stats['score'] >= 30:
            return f"High threat score ({stats['score']})"
        elif len(stats['signatures']) >= 3:
            return f"Multiple attack types ({len(stats['signatures'])})"
        else:
            return "Suspicious activity"
    
    async def _auto_respond(self, threat: Dict):
        """ìžë™ ëŒ€ì‘"""
        ip = threat['ip']
        
        if ip in self.blocked_ips:
            print(f"     â„¹ï¸  Already blocked")
            return
        
        print(f"     ðŸ”’ Auto-blocking...")
        
        try:
            # IP ì°¨ë‹¨
            import subprocess
            cmd = f"sudo iptables -A INPUT -s {ip} -j DROP"
            subprocess.run(cmd, shell=True, check=True)
            
            self.blocked_ips.add(ip)
            
            # ë¡œê·¸ ê¸°ë¡
            self._log_action('BLOCK', ip, threat)
            
            print(f"     âœ… Blocked successfully")
        
        except Exception as e:
            print(f"     âŒ Block failed: {e}")
    
    async def _generate_rules(self, analysis_result: Dict):
        """AI ì¶”ì²œ ê¸°ë°˜ ë£° ìƒì„±"""
        suggestions = analysis_result.get('rule_suggestions', [])
        
        for suggestion in suggestions:
            rule_type = suggestion['type']
            reason = suggestion['reason']
            
            print(f"     Creating {rule_type} rule...")
            
            rule_content = await self.rule_generator.generate_rule(
                rule_type,
                reason,
                suggestion
            )
            
            if rule_content:
                result = await self.rule_manager.add_rule(
                    rule_content,
                    f"AI-generated: {reason}",
                    auto_reload=True
                )
                
                if result['success']:
                    print(f"     âœ… Rule created successfully")
                else:
                    print(f"     âŒ Failed: {result.get('error')}")
    
    def _log_action(self, action: str, ip: str, details: Dict):
        """ì•¡ì…˜ ë¡œê·¸ ê¸°ë¡"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "ip": ip,
            "details": details
        }
        
        log_file = self.log_dir / "actions.log"
        
        with open(log_file, 'a') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def _log_error(self, error: str):
        """ì—ëŸ¬ ë¡œê·¸"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "error": error
        }
        
        log_file = self.log_dir / "errors.log"
        
        with open(log_file, 'a') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    def _group_by_severity(self, logs: List[Dict]) -> Dict:
        from collections import Counter
        severities = [log['severity'] for log in logs]
        return dict(Counter(severities))
    
    def _get_top_ips(self, logs: List[Dict], limit: int) -> List[str]:
        from collections import Counter
        ips = [log['src_ip'] for log in logs]
        return [ip for ip, _ in Counter(ips).most_common(limit)]
    
    def _get_top_signatures(self, logs: List[Dict], limit: int) -> List[str]:
        from collections import Counter
        sigs = [log['signature'] for log in logs]
        return [sig for sig, _ in Counter(sigs).most_common(limit)]
    
    def _group_by_attack_type(self, logs: List[Dict]) -> Dict:
        from collections import Counter
        types = [log.get('attack_type', 'Unknown') for log in logs]
        return dict(Counter(types))
    
    def _calculate_success_rate(self, logs: List[Dict]) -> float:
        if not logs:
            return 0.0
        successful = sum(1 for log in logs if log.get('success', False))
        return round((successful / len(logs)) * 100, 2)


async def main():
    agent = SecurityAgent()
    await agent.start()

if __name__ == "__main__":
    asyncio.run(main())